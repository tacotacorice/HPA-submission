{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Single Cells Model ResNet50 and EFF_B4\n\n!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n\nimport sys\npackage_path = '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\n\n!ls ../input/efficientnet-pytorch/EfficientNet-PyTorch\n%cd /kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\nfrom efficientnet_pytorch import EfficientNet\n\nimport pandas as pd\nimport numpy as np\nfrom fastai.vision.all import *\nimport pickle\nimport os\nif not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n        os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/resnet50/resnet50.pth' '/root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth'\n!cp '../input/efficientnet-pytorch-pretrained/adv-efficientnet-b4-44fb3a87.pth' '/root/.cache/torch/hub/checkpoints/'\n!cp '../input/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth' '/root/.cache/torch/hub/checkpoints/'\n\npath = Path('../input/hpa-cell-tiles-sample-balanced-dataset')\n\ndf = pd.read_csv(path/'cell_df.csv')\n\nlabels = [str(i) for i in range(19)]\nfor x in labels: df[x] = df['image_labels'].apply(lambda r: int(x in r.split('|')))\n\n\ndfs = df.sample(frac=1, random_state=42)\ndfs = dfs.reset_index(drop=True)\n\nunique_counts = {}\nfor lbl in labels:\n    unique_counts[lbl] = len(dfs[dfs.image_labels == lbl])\n\nfull_counts = {}\nfor lbl in labels:\n    count = 0\n    for row_label in dfs['image_labels']:\n        if lbl in row_label.split('|'): count += 1\n    full_counts[lbl] = count\n    \ncounts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\ncounts = np.array(sorted(counts, key=lambda x:-x[1]))\ncounts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\ncounts.set_index('label').T\n\nnfold = 5\nseed = 42\n\ny = dfs[labels].values\nX = dfs[['image_id', 'cell_id']].values\n\ndfs['fold'] = np.nan\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed,shuffle=True)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    dfs.iloc[test_index, -1] = i\n    \ndfs['fold'] = dfs['fold'].astype('int')\ndfs['is_valid'] = False\ndfs['is_valid'][dfs['fold'] == 0] = True\n\ndfs.is_valid.value_counts()\n\ndef get_x(r):return path/'cells'/(r['image_id']+'_'+str(r['cell_id'])+'.jpg')\ndef get_y(r): return r['image_labels'].split('|')\nget_y(dfs.loc[12])\n\nsample_stats = ([0.07237246, 0.04476176, 0.07661699], [0.17179589, 0.10284516, 0.14199627])\n\nitem_tfms = RandomResizedCrop(640, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(flip_vert=True, size=128, max_warp=0), Normalize.from_stats(*sample_stats)]\nbs=256\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(vocab=labels)),\n                splitter=ColSplitter(col='is_valid'),\n                get_x=get_x,\n                get_y=get_y,\n                item_tfms=item_tfms,\n                batch_tfms=batch_tfms\n                )\ndls = dblock.dataloaders(dfs, bs=bs)\n\ndls.show_batch(nrows=3, ncols=3)\n\nlearn0 = cnn_learner(dls, resnet50, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()\n\ndef get_learner(lr=1e-3):\n    opt_func = partial(Adam, lr=lr, wd=0.01, eps=1e-8)\n  \n    model = EfficientNet.from_pretrained(\"efficientnet-b4\", advprop=True)\n    \n    #model._fc = nn.Linear(1280, data.c)# the last layer... # works for b0,b1\n    #model._fc = nn.Linear(1536, data.c)# the last layer... B3\n    model._fc = nn.Linear(1792, dls.c)# the last layer... B4\n    ##model._fc = nn.Linear(2048, dls.c)# the last layer... B5\n    #model._fc = nn.Linear(2304, dls.c)# the last layer... B6\n    #model._fc = nn.Linear(2560, dls.c)# the last layer... B7\n    #model._fc = nn.Linear(2816, data.c)# the last layer... B8\n\n    learn = Learner(\n        dls, model, opt_func=opt_func,\n        metrics=[accuracy_multi, PrecisionMulti()]\n        ).to_fp16()\n    return learn\n\nlearn1=get_learner()\n\n!mkdir ./models\n\n!cp ../input/fastai-cell-tile-prototyping-th2/models/trained_model.pth ./models\n!mv ./models/trained_model.pth ./models/trained_model0.pth\nlearn0 = learn0.load(\"trained_model0\")\n\n!cp ../input/fastai-cell-tile-prototyping-th2-effb4/models/trained_model.pth ./models\n!mv ./models/trained_model.pth ./models/trained_model1.pth\nlearn1 = learn1.load(\"trained_model1\")\n","metadata":{"papermill":{"duration":68.217355,"end_time":"2021-05-08T10:59:23.696007","exception":false,"start_time":"2021-05-08T10:58:15.478652","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Commit options\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nsub = pd.read_csv(\"../input/hpa-single-cell-image-classification/sample_submission.csv\")\ndf=sub\ndata_df=sub\ntest_df=sub\ndebug=False\ncommit=12\n\nif len(sub) == 559:\n    sub=sub[:commit]\n    df=df[:commit]\n    data_df=data_df[:commit]\n    debug=True\nelse:\n    sub=sub\n    df=df\n    data_df=data_df\n\nbs=500 #How many images to process in each batch #If this value is set too large, a memory leak will occur\n    ","metadata":{"papermill":{"duration":0.05084,"end_time":"2021-05-08T10:59:24.373812","exception":false,"start_time":"2021-05-08T10:59:24.322972","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hpacellsegmentatormaster install\n\n!pip install ../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master/\n!pip install ../input/hpapytorchzoozip/pytorch_zoo-master/\n!pip install ../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl","metadata":{"papermill":{"duration":54.298472,"end_time":"2021-05-08T11:00:18.706648","exception":false,"start_time":"2021-05-08T10:59:24.408176","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sub_process(cell_df0,preds):\n    cell_df0['cls'] = ''\n\n    threshold = 0.0\n\n    for i in range(preds.shape[0]): \n        p = torch.nonzero(preds[i] > threshold).squeeze().numpy().tolist()\n        if type(p) != list: p = [p]\n        if len(p) == 0: cls = [(preds[i].argmax().item(), preds[i].max().item())]\n        else: cls = [(x, preds[i][x].item()) for x in p]\n        cell_df0['cls'].loc[i] = cls\n\n    return cell_df0","metadata":{"papermill":{"duration":0.048396,"end_time":"2021-05-08T11:00:18.793612","exception":false,"start_time":"2021-05-08T11:00:18.745216","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ensemble_func(cell_df,cell_df1):\n    \n    test=cell_df.copy()\n        \n    for i in range(len(cell_df)):\n        df=pd.DataFrame(cell_df.cls[i])\n        df_pred=0.6*pd.DataFrame(cell_df.cls[i])+0.4*pd.DataFrame(cell_df1.cls[i])\n        df[1]=df_pred[1]\n        test.cls[i]=df.values.tolist()\n    \n    return test","metadata":{"papermill":{"duration":0.045931,"end_time":"2021-05-08T11:00:18.877301","exception":false,"start_time":"2021-05-08T11:00:18.83137","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segmentation,Cropping into singel cells and Inference\n\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nfrom tqdm import tqdm\nimport os\nimport numpy as np\nimport pandas as pd\n\nNUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cuda\",\n    padding=True,\n    multi_channel_model=True,\n)\n\n\ndef get_segment_mask(data_id, root='../input/hpa-single-cell-image-classification/test/'):\n    r = [os.path.join(root, f'{data_id}_red.png')]\n    y = [os.path.join(root, f'{data_id}_yellow.png')]\n    b = [os.path.join(root, f'{data_id}_blue.png')]\n    data = [r, y, b]\n    nuc_segmentations = segmentator.pred_nuclei(data[2])\n    cell_segmentations = segmentator.pred_cells(data)\n    nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    return nuclei_mask, cell_mask\n\nfrom fastai.vision.all import *\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\npath = Path('../input/hpa-single-cell-image-classification')\nROOT = '../input/hpa-single-cell-image-classification/'\ntrain_or_test = 'test'\n\ndef get_cropped_cell(img, msk):\n    bmask = msk.astype(int)[...,None]\n    masked_img = img * bmask\n    true_points = np.argwhere(bmask)\n    top_left = true_points.min(axis=0)\n    bottom_right = true_points.max(axis=0)\n    cropped_arr = masked_img[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n    return cropped_arr\n\ndef get_stats(cropped_cell):\n    x = (cropped_cell/255.0).reshape(-1,3).mean(0)\n    x2 = ((cropped_cell/255.0)**2).reshape(-1,3).mean(0)\n    return x, x2\n\ndef read_img(image_id, color, train_or_test='test', image_size=None):\n    filename = f'{ROOT}/{train_or_test}/{image_id}_{color}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.max() > 255:\n        img_max = img.max()\n        img = (img/255).astype('uint8')\n    return img\n\nimport base64\nimport numpy as np\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\n\n\ndef encode_binary_mask(mask: np.ndarray) -> t.Text:\n  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n  # check input mask --\n  if mask.dtype != np.bool:\n    raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n  mask = np.squeeze(mask)\n  if len(mask.shape) != 2:\n    raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n  mask_to_encode = mask_to_encode.astype(np.uint8)\n  mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n  base64_str = base64.b64encode(binary_str)\n  return base64_str.decode('ascii')\n\nnum_files = len(df)\nsub_full = pd.DataFrame(columns=[\"ID\",\"ImageWidth\",\"ImageHeight\",\"PredictionString\"])\n\ndata_size = len(data_df)\n\nfor i in range(0, data_size, bs):\n    print('!!!!', i, '!!!!')\n    \n    x_tot,x2_tot = [],[]\n    all_cells = []\n    \n    start = i\n    end = min(len(data_df), start + bs)\n    test_df = data_df[start:end]\n\n    root = './temp/cells'\n    os.makedirs(root, exist_ok=True)\n\n    print('---- start mask write ----')\n    for image_id in tqdm(test_df.ID.to_list()):\n        nuc, cell = get_segment_mask(image_id)\n\n        red = read_img(image_id, \"red\", train_or_test, None)#512\n        green = read_img(image_id, \"green\", train_or_test, None)\n        blue = read_img(image_id, \"blue\", train_or_test, None)\n        cell_mask = cv2.resize(cell,red.shape,interpolation=cv2.INTER_NEAREST)#cell##np.load(f'/kaggle/working/test_mask/{image_id}_cell.npy')\n        #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n        stacked_image = np.transpose(np.array([blue, green, red]), (1,2,0))\n\n        for j in range(1, np.max(cell_mask)):\n       \n            bmask = (cell_mask == j)\n            enc = encode_binary_mask(bmask)\n            cropped_cell = get_cropped_cell(stacked_image, bmask)\n            fname = f'{image_id}_{j}.jpg'\n            ##im = cv2.imencode('.jpg', cropped_cell)[1]\n            ##img_out.writestr(fname, im)\n            cv2.imwrite(f'./temp/cells/{fname}', cropped_cell)\n            x, x2 = get_stats(cropped_cell)\n            x_tot.append(x)\n            x2_tot.append(x2)\n            all_cells.append({\n                'image_id': image_id,\n                'fname': fname,\n                'r_mean': x[0],\n                'g_mean': x[1],\n                'b_mean': x[2],\n                'cell_id': j,\n                'size1': cropped_cell.shape[0],\n                'size2': cropped_cell.shape[1],\n                'enc': enc,\n            })\n      \n    path = Path('/kaggle/working/temp')\n\n    cell_df = pd.DataFrame(all_cells)###\n    test_dl0 = learn0.dls.test_dl(cell_df)\n    test_dl1 = learn1.dls.test_dl(cell_df)\n\n    preds0, _ = learn0.tta(dl=test_dl0,n=3)\n    preds1, _ = learn1.tta(dl=test_dl1,n=2)\n    ##preds1=torch.tensor(seresnext50(cell_df))\n    \n    !rm /kaggle/working/temp/cells/* \n    !rmdir /kaggle/working/temp/cells  \n    !rmdir /kaggle/working/temp\n    \n    print('---- finish mask write ----')\n\n    sub0=sub_process(cell_df,preds0)\n    cell_df1=cell_df.copy()\n    sub1=sub_process(cell_df1,preds1)\n    \n    cell_df0=ensemble_func(sub0,sub1)\n    \n    def combine(r):\n        cls = r[0]\n        enc = r[1]\n        classes = [str(int(c[0])) + ' ' + str(c[1]) + ' ' + enc for c in cls]\n        return ' '.join(classes)\n\n    cell_df0['pred'] = cell_df0[['cls', 'enc']].apply(combine, axis=1)\n\n    subm = cell_df0.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n\n    sample_submission = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n\n    sub = pd.merge(\n        sample_submission,\n        subm,\n        how=\"left\",\n        left_on='ID',\n        right_on='image_id',\n    )\n\n    def isNaN(num):\n        return num != num\n\n    for i, row in sub.iterrows():\n        if isNaN(row['pred']): continue\n        sub.PredictionString.loc[i] = row['pred']\n\n    sub = sub[sample_submission.columns]\n    sub_full=pd.concat([sub_full,sub[start:end]])\nsub_full.to_csv('submission0.csv', index=False)\n    \nss_df=sub_full     \n","metadata":{"papermill":{"duration":195.176955,"end_time":"2021-05-08T11:03:59.98937","exception":false,"start_time":"2021-05-08T11:00:44.812415","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n\nimport tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\nimport torch\n\nimport pandas as pd\nimport os\n\nimport efficientnet.tfkeras as efn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Built In Imports\nfrom collections import Counter\nfrom datetime import datetime\nimport multiprocessing\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport tqdm\nimport time\nimport gzip\nimport sys\nimport ast\nimport csv; csv.field_size_limit(sys.maxsize)\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\nimport typing as t\nimport base64\nimport zlib\n","metadata":{"papermill":{"duration":57.304501,"end_time":"2021-05-08T11:04:58.399606","exception":false,"start_time":"2021-05-08T11:04:01.095105","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image Level Model SEResNext50_32x4d\n\ndef seres_imlevel():\n\n    # ====================================================\n    # Directory settings\n    # ====================================================\n    import os\n\n    MODEL_DIR = '../input/seres-imlevel-folds/'\n\n    OUTPUT_DIR = './'\n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n\n    TEST_PATH = '../input/hpa-single-cell-image-classification/test'\n\n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        debug=False\n        num_workers=4\n        model_name='seresnext50_32x4d'#'resnet200d_320'#'resnext50_32x4d'\n        size=640\n        batch_size=16#64\n        seed=42\n        target_size=19\n        target_cols=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']\n\n        n_fold=4\n        trn_fold=[0, 1, 2]#, 3]\n\n    # ====================================================\n    # Library\n    # ====================================================\n    import sys\n    sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\n    import os\n    import math\n    import time\n    import random\n    import shutil\n    from pathlib import Path\n    from contextlib import contextmanager\n    from collections import defaultdict, Counter\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n\n    from sklearn import preprocessing\n    from sklearn.metrics import roc_auc_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    from tqdm.auto import tqdm\n    from functools import partial\n\n    import cv2\n    from PIL import Image\n\n    from matplotlib import pyplot as plt\n\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD\n    import torchvision.models as models\n    from torch.nn.parameter import Parameter\n    from torch.utils.data import DataLoader, Dataset\n    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\n    from albumentations import (\n        Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n        RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n        IAAAdditiveGaussianNoise, Transpose\n        )\n    from albumentations.pytorch import ToTensorV2\n    from albumentations import ImageOnlyTransform\n\n    import timm\n\n    from torch.cuda.amp import autocast, GradScaler\n\n    import warnings \n    warnings.filterwarnings('ignore')\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        scores = []\n        for i in range(y_true.shape[1]):\n            score = roc_auc_score(y_true[:,i], y_pred[:,i])\n            scores.append(score)\n        avg_score = np.mean(scores)\n        return avg_score, scores\n\n\n    def get_result(result_df):\n        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n        labels = result_df[CFG.target_cols].values\n        score, scores = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n\n\n    @contextmanager\n    def timer(name):\n        t0 = time.time()\n        LOGGER.info(f'[{name}] start')\n        yield\n        LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\n    def init_logger(log_file=OUTPUT_DIR+'inference.log'):\n        from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=log_file)\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = init_logger()\n\n\n    def seed_torch(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_torch(seed=CFG.seed)\n\n    test = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    print(test.shape)\n    test.head()\n\n    if CFG.debug:\n        test = test.head()\n\n    # ====================================================\n    # Dataset\n    # ====================================================\n    class TestDataset(Dataset):\n        def __init__(self, df, transform=None):\n            self.df = df\n            self.file_names = df['ID'].values\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.df)\n\n        def __getitem__(self, idx):\n            file_name = self.file_names[idx]\n            file_path = f'{TEST_PATH}/{file_name}_green.png'\n            image = cv2.imread(file_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            if self.transform:\n                augmented = self.transform(image=image)\n                image = augmented['image']\n            return image\n\n    # ====================================================\n    # Transforms\n    # ====================================================\n    def get_transforms(*, data):\n\n        if data == 'train':\n            return Compose([\n                Resize(CFG.size, CFG.size),\n                Normalize(\n                    mean=[0.485, 0.456, 0.406],\n                    std=[0.229, 0.224, 0.225],\n                ),\n                ToTensorV2(),\n            ])\n\n        elif data == 'valid':\n            return Compose([\n                Resize(CFG.size, CFG.size),\n                Normalize(\n                    mean=[0.485, 0.456, 0.406],\n                    std=[0.229, 0.224, 0.225],\n                ),\n                ToTensorV2(),\n            ])\n\n    # ====================================================\n    # MODEL\n    # ====================================================\n    class CustomResNext(nn.Module):\n        def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n            super().__init__()\n            self.model = timm.create_model(model_name, pretrained=pretrained)\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(n_features, CFG.target_size)\n\n        def forward(self, x):\n            x = self.model(x)\n            return x\n\n    class CustomEfficientNet(nn.Module):\n        def __init__(self, model_name=CFG.model_name, pretrained=False):\n            super().__init__()\n            self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n        def forward(self, x):\n            x = self.model(x)\n            return x\n\n    # ====================================================\n    # Helper functions\n    # ====================================================\n    def inference(model, states, test_loader, device):\n        model.to(device)\n        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n        probs = []\n        for i, (images) in tk0:\n            images = images.to(device)\n            avg_preds = []\n            for state in states:\n                model.load_state_dict(state['model'])\n                model.eval()\n                with torch.no_grad():\n                    y_preds = model(images)\n                avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n            avg_preds = np.mean(avg_preds, axis=0)\n            probs.append(avg_preds)\n        probs = np.concatenate(probs)\n        return probs\n\n    def inference0(models, states, test_loader, device):\n        model.to(device)\n        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n        probs = []\n        for i, (images) in tk0:\n            images = images.to(device)\n            avg_preds = []\n            for state in states:\n                with torch.no_grad():\n                    y_preds1 = model(images)\n                    y_preds2 = model(images.flip(-1))\n                y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) / 2\n                avg_preds.append(y_preds)\n            avg_preds = np.mean(avg_preds, axis=0)\n            probs.append(avg_preds)\n        probs = np.concatenate(probs)\n        return probs\n\n    # ====================================================\n    # inference\n    # ====================================================\n    model = CustomResNext(CFG.model_name, pretrained=False)\n    states = [torch.load(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True)\n    predictions = inference(model, states, test_loader, device)\n    \n    # submission\n    test[CFG.target_cols] = predictions\n    #test[['ID'] + CFG.target_cols].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n    #test.head()\n    \n    return test","metadata":{"papermill":{"duration":0.099961,"end_time":"2021-05-08T11:04:58.548546","exception":false,"start_time":"2021-05-08T11:04:58.448585","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image Level Model EFF B3 not used\ndef eff_imlevel():\n    # ====================================================\n    # Directory settings\n    # ====================================================\n    import os\n\n    MODEL_DIR = '../input/effb3-image-level/'\n\n    OUTPUT_DIR = './'\n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n\n    TEST_PATH = '../input/hpa-single-cell-image-classification/test'\n    \n    # ====================================================\n    # CFG\n    # ====================================================\n    class CFG:\n        debug=False\n        num_workers=4\n        model_name='tf_efficientnet_b3'\n        size=640\n        batch_size=8\n        seed=42\n        target_size=19\n        target_cols=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']\n\n        n_fold=4\n        trn_fold=[0, 1, 2]\n\n    # ====================================================\n    # Library\n    # ====================================================\n    import sys\n    sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\n    import os\n    import math\n    import time\n    import random\n    import shutil\n    from pathlib import Path\n    from contextlib import contextmanager\n    from collections import defaultdict, Counter\n\n    import scipy as sp\n    import numpy as np\n    import pandas as pd\n\n    from sklearn import preprocessing\n    from sklearn.metrics import roc_auc_score\n    from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n    from tqdm.auto import tqdm\n    from functools import partial\n\n    import cv2\n    from PIL import Image\n\n    from matplotlib import pyplot as plt\n\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.optim import Adam, SGD\n    import torchvision.models as models\n    from torch.nn.parameter import Parameter\n    from torch.utils.data import DataLoader, Dataset\n    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\n    from albumentations import (\n        Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n        RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n        IAAAdditiveGaussianNoise, Transpose\n        )\n    from albumentations.pytorch import ToTensorV2\n    from albumentations import ImageOnlyTransform\n\n    import timm\n\n    from torch.cuda.amp import autocast, GradScaler\n\n    import warnings \n    warnings.filterwarnings('ignore')\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # ====================================================\n    # Utils\n    # ====================================================\n    def get_score(y_true, y_pred):\n        scores = []\n        for i in range(y_true.shape[1]):\n            score = roc_auc_score(y_true[:,i], y_pred[:,i])\n            scores.append(score)\n        avg_score = np.mean(scores)\n        return avg_score, scores\n\n\n    def get_result(result_df):\n        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n        labels = result_df[CFG.target_cols].values\n        score, scores = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n\n\n    @contextmanager\n    def timer(name):\n        t0 = time.time()\n        LOGGER.info(f'[{name}] start')\n        yield\n        LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\n    def init_logger(log_file=OUTPUT_DIR+'inference.log'):\n        from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n        logger = getLogger(__name__)\n        logger.setLevel(INFO)\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        handler2 = FileHandler(filename=log_file)\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n        logger.addHandler(handler2)\n        return logger\n\n    LOGGER = init_logger()\n\n\n    def seed_torch(seed=42):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n\n    seed_torch(seed=CFG.seed)\n\n    test = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    print(test.shape)\n    test.head()\n\n    if CFG.debug:\n        test = test.head()\n\n    # ====================================================\n    # Dataset\n    # ====================================================\n    class TestDataset(Dataset):\n        def __init__(self, df, transform=None):\n            self.df = df\n            self.file_names = df['ID'].values\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.df)\n\n        def __getitem__(self, idx):\n            file_name = self.file_names[idx]\n            file_path = f'{TEST_PATH}/{file_name}_green.png'\n            image = cv2.imread(file_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            if self.transform:\n                augmented = self.transform(image=image)\n                image = augmented['image']\n            return image\n\n    # ====================================================\n    # Transforms\n    # ====================================================\n    def get_transforms(*, data):\n\n        if data == 'train':\n            return Compose([\n                Resize(CFG.size, CFG.size),\n                Normalize(\n                    mean=[0.485, 0.456, 0.406],\n                    std=[0.229, 0.224, 0.225],\n                ),\n                ToTensorV2(),\n            ])\n\n        elif data == 'valid':\n            return Compose([\n                Resize(CFG.size, CFG.size),\n                Normalize(\n                    mean=[0.485, 0.456, 0.406],\n                    std=[0.229, 0.224, 0.225],\n                ),\n                ToTensorV2(),\n            ])\n\n    # ====================================================\n    # MODEL\n    # ====================================================\n    class CustomResNext(nn.Module):\n        def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n            super().__init__()\n            self.model = timm.create_model(model_name, pretrained=pretrained)\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(n_features, CFG.target_size)\n\n        def forward(self, x):\n            x = self.model(x)\n            return x\n\n    class CustomEfficientNet(nn.Module):\n        def __init__(self, model_name=CFG.model_name, pretrained=False):\n            super().__init__()\n            self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n        def forward(self, x):\n            x = self.model(x)\n            return x\n\n    # ====================================================\n    # Helper functions\n    # ====================================================\n    def inference(model, states, test_loader, device):\n        model.to(device)\n        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n        probs = []\n        for i, (images) in tk0:\n            images = images.to(device)\n            avg_preds = []\n            for state in states:\n                model.load_state_dict(state['model'])\n                model.eval()\n                with torch.no_grad():\n                    y_preds = model(images)\n                avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n            avg_preds = np.mean(avg_preds, axis=0)\n            probs.append(avg_preds)\n        probs = np.concatenate(probs)\n        return probs\n\n    def inference0(models, states, test_loader, device):\n        model.to(device)\n        tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n        probs = []\n        for i, (images) in tk0:\n            images = images.to(device)\n            avg_preds = []\n            for state in states:\n                with torch.no_grad():\n                    y_preds1 = model(images)\n                    y_preds2 = model(images.flip(-1))\n                y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) / 2\n                avg_preds.append(y_preds)\n            avg_preds = np.mean(avg_preds, axis=0)\n            probs.append(avg_preds)\n        probs = np.concatenate(probs)\n        return probs\n\n    # ====================================================\n    # inference\n    # ====================================================\n    ##model = CustomResNext(CFG.model_name, pretrained=False)\n    model = CustomEfficientNet(CFG.model_name, pretrained=False)\n    states = [torch.load(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True)\n    predictions = inference(model, states, test_loader, device)\n    # submission\n    test[CFG.target_cols] = predictions\n    #test[['ID'] + CFG.target_cols].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n    #test.head()\n    \n    return test","metadata":{"papermill":{"duration":0.095243,"end_time":"2021-05-08T11:04:58.692278","exception":false,"start_time":"2021-05-08T11:04:58.597035","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im1=seres_imlevel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##im2=eff_imlevel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image Level Model EFF B7(TPU) and Inference \n\nsub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n\nif sub_df.shape[0] != 559:\n    def auto_select_accelerator():\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\n        except ValueError:\n            strategy = tf.distribute.get_strategy()\n        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n        return strategy\n\n\n    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n        def decode(path):\n            file_bytes = tf.io.read_file(path)\n            if ext == 'png':\n                img = tf.image.decode_png(file_bytes, channels=3)\n            elif ext in ['jpg', 'jpeg']:\n                img = tf.image.decode_jpeg(file_bytes, channels=3)\n            else:\n                raise ValueError(\"Image extension not supported\")\n\n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img, target_size)\n\n            return img\n\n        def decode_with_labels(path, label):\n            return decode(path), label\n\n        return decode_with_labels if with_labels else decode\n\n\n    def build_augmenter(with_labels=True):\n        def augment(img):\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            return img\n\n        def augment_with_labels(img, label):\n            return augment(img), label\n\n        return augment_with_labels if with_labels else augment\n\n\n    def build_dataset(paths, labels=None, bsize=32, cache=True,\n                      decode_fn=None, augment_fn=None,\n                      augment=True, repeat=True, shuffle=1024, \n                      cache_dir=\"\"):\n        if cache_dir != \"\" and cache is True:\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if decode_fn is None:\n            decode_fn = build_decoder(labels is not None)\n\n        if augment_fn is None:\n            augment_fn = build_augmenter(labels is not None)\n\n        AUTO = tf.data.experimental.AUTOTUNE\n        slices = paths if labels is None else (paths, labels)\n\n        dset = tf.data.Dataset.from_tensor_slices(slices)\n        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n        dset = dset.cache(cache_dir) if cache else dset\n        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        dset = dset.repeat() if repeat else dset\n        dset = dset.shuffle(shuffle) if shuffle else dset\n        dset = dset.batch(bsize).prefetch(AUTO)\n\n        return dset\n\n    COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n    strategy = auto_select_accelerator()\n    BATCH_SIZE = strategy.num_replicas_in_sync * 16\n\n    ##MSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 640)\n\n    load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n    sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    #sub_df = ss_df.copy()\n\n    sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n\n    for i in range(19):\n        sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n\n    ###!= 559\n    test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n    #test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_blue.png'\n    ##test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_red.png'\n    #test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_yellow.png'\n    # Get the multi-labels\n    label_cols = sub_df.columns[1:]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\n    #test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]))\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n        model = tf.keras.models.load_model(\n            '../input/hpaclassificationefnb7train2weight/model_green.h5'\n            #'../input/hpa-classification-efnb7-train/model_green.h5'\n            #'../input/hpa-classification-efnb7-train-blue/model_blue.h5'\n            #'../input/hpa-classification-efnb7-train-red/model_red.h5'\n            #'../input/hpa-classification-efnb7-train-yellow/model_yellow.h5'\n        )\n\n    model.summary()\n    \n    im2=model.predict(dtest, verbose=1)\n    sub_df[label_cols]=0.5*im1[label_cols]+0.5*im2\n    \n\n    sub_df.head()\n\n    ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n\n    for i in range(ss_df.shape[0]):\n        if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n            continue\n        a = ss_df.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/3)):\n            for k in range(19):\n                if int(b[0 + 3 * j]) == k:\n\n                    c = b[0 + 3 * j + 1]               \n                    b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.5 + float(c) * 0.5)\n\n        ss_df.loc[i,'PredictionString'] = ' '.join(b)\n\n    ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n    ss_df.to_csv('submission.csv',index = False)\nelse:\n    def auto_select_accelerator():\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\n        except ValueError:\n            strategy = tf.distribute.get_strategy()\n        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n        return strategy\n\n\n    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n        def decode(path):\n            file_bytes = tf.io.read_file(path)\n            if ext == 'png':\n                img = tf.image.decode_png(file_bytes, channels=3)\n            elif ext in ['jpg', 'jpeg']:\n                img = tf.image.decode_jpeg(file_bytes, channels=3)\n            else:\n                raise ValueError(\"Image extension not supported\")\n\n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img, target_size)\n\n            return img\n\n        def decode_with_labels(path, label):\n            return decode(path), label\n\n        return decode_with_labels if with_labels else decode\n\n\n    def build_augmenter(with_labels=True):\n        def augment(img):\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            return img\n\n        def augment_with_labels(img, label):\n            return augment(img), label\n\n        return augment_with_labels if with_labels else augment\n\n\n    def build_dataset(paths, labels=None, bsize=32, cache=True,\n                      decode_fn=None, augment_fn=None,\n                      augment=True, repeat=True, shuffle=1024, \n                      cache_dir=\"\"):\n        if cache_dir != \"\" and cache is True:\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if decode_fn is None:\n            decode_fn = build_decoder(labels is not None)\n\n        if augment_fn is None:\n            augment_fn = build_augmenter(labels is not None)\n\n        AUTO = tf.data.experimental.AUTOTUNE\n        slices = paths if labels is None else (paths, labels)\n\n        dset = tf.data.Dataset.from_tensor_slices(slices)\n        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n        dset = dset.cache(cache_dir) if cache else dset\n        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        dset = dset.repeat() if repeat else dset\n        dset = dset.shuffle(shuffle) if shuffle else dset\n        dset = dset.batch(bsize).prefetch(AUTO)\n\n        return dset\n\n    COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n    strategy = auto_select_accelerator()\n    BATCH_SIZE = strategy.num_replicas_in_sync * 16\n    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 640)\n\n    load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n    sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    sub_df = ss_df.copy()\n\n    sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n\n    for i in range(19):\n        sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n\n\n    test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n    #test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_blue.png'\n    #test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_red.png'\n    #test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_yellow.png'\n    # Get the multi-labels\n    label_cols = sub_df.columns[1:]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n        model = tf.keras.models.load_model(\n            '../input/hpaclassificationefnb7train2weight/model_green.h5'\n            ##'../input/hpa-classification-efnb7-train/model_green.h5'\n            ##'../input/hpa-classification-efnb7-train-blue/model_blue.h5'\n            #'../input/hpa-classification-efnb7-train-red/model_red.h5'\n            ##'../input/hpa-classification-efnb7-train-yellow/model_yellow.h5'\n        )\n\n    model.summary()\n    im2=model.predict(dtest, verbose=1)\n    sub_df[label_cols]=0.5*im1[label_cols][:commit]+0.5*im2\n\n    sub_df.head()\n\n    ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n\n    for i in range(ss_df.shape[0]):\n        if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n            continue\n        a = ss_df.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/3)):\n            for k in range(19):\n                if int(b[0 + 3 * j]) == k:\n\n                    c = b[0 + 3 * j + 1]               \n                    b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.5 + float(c) * 0.5)\n\n        ss_df.loc[i,'PredictionString'] = ' '.join(b)\n\n    ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n    ss_df.to_csv('submission.csv',index = False)","metadata":{"papermill":{"duration":75.111546,"end_time":"2021-05-08T11:06:13.852294","exception":false,"start_time":"2021-05-08T11:04:58.740748","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.049298,"end_time":"2021-05-08T11:06:13.950551","exception":false,"start_time":"2021-05-08T11:06:13.901253","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}